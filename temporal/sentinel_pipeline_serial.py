import os
import json
import yaml
import zipfile
import shutil
import requests
import numpy as np
import rasterio
import geopandas as gpd
import joblib
from pathlib import Path
from datetime import date, datetime
from dotenv import load_dotenv
from rasterio.mask import mask
from rasterio.warp import reproject, Resampling


def file_exists(path: str) -> bool:
    return os.path.exists(path)


def dir_has_files(path: str) -> bool:
    return os.path.exists(path) and bool(os.listdir(path))


def load_geojson(path: str) -> dict:
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ AOI geojson not found at: {path}")
    with open(path, "r") as f:
        return json.load(f)


def load_config(config_path: str = "config/config.yaml") -> dict:
    env_path = Path(__file__).resolve().parent / ".env"
    load_dotenv(dotenv_path=env_path)

    config_path = Path(config_path)
    if not config_path.is_absolute():
        config_path = Path(__file__).resolve().parent / config_path

    if not config_path.exists():
        raise FileNotFoundError(f"âŒ Config file not found at {config_path}")

    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    config.setdefault("credentials", {})
    config["credentials"]["username"] = config["credentials"].get("username") or os.getenv("COPERNICUS_USERNAME")
    config["credentials"]["password"] = config["credentials"].get("password") or os.getenv("COPERNICUS_PASSWORD")

    if "aoi" in config and isinstance(config["aoi"], dict):
        geo_path = Path(config["aoi"]["geojson_path"])
        # if not geo_path.is_absolute():
        #     geo_path = Path(__file__).resolve().parent / geo_path

        if not geo_path.is_absolute():
            geo_path = Path.cwd() / geo_path    
        config["aoi"]["geojson_path"] = str(geo_path)

    if "date_range" not in config:
        start = config.get("project", {}).get("start_date", "2022-01-01")
        config["date_range"] = {
            "start": str(start),
            "end": date.today().isoformat()
        }

    return config


def get_token(username: str, password: str) -> str:
    url = "https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token"
    data = {
        "grant_type": "password",
        "client_id": "cdse-public",
        "username": username,
        "password": password
    }
    response = requests.post(url, data=data)
    response.raise_for_status()
    return response.json()["access_token"]


def search_metadata(token: str, geojson: dict, start: str, end: str) -> list:
    url = "https://sh.dataspace.copernicus.eu/api/v1/catalog/1.0.0/search"
    headers = {"Authorization": f"Bearer {token}", "Content-Type": "application/json"}
    geometry = geojson["features"][0]["geometry"]
    payload = {
        "intersects": geometry,
        "datetime": f"{start}T00:00:00Z/{end}T23:59:59Z",
        "collections": ["sentinel-2-l2a"],
        "limit": 100
    }
    response = requests.post(url, headers=headers, json=payload)
    response.raise_for_status()
    return response.json()["features"]


def download_safe(product_id: str, token: str, download_dir: str) -> str:
    odata_url = f"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Name eq '{product_id}'"
    odata_response = requests.get(odata_url)
    odata_response.raise_for_status()
    odata_id = odata_response.json()["value"][0]["Id"]
    download_url = f"https://download.dataspace.copernicus.eu/odata/v1/Products({odata_id})/$value"

    headers = {"Authorization": f"Bearer {token}", "Accept": "*/*"}
    response = requests.get(download_url, headers=headers, stream=True)
    response.raise_for_status()

    os.makedirs(download_dir, exist_ok=True)
    file_path = os.path.join(download_dir, f"{product_id}.zip")
    with open(file_path, "wb") as f:
        for chunk in response.iter_content(8192):
            if chunk:
                f.write(chunk)
    return file_path


def unzip_safe(zip_path: str, final_target_path: str, short_temp_path: str = "/tmp/safe_tmp") -> str:
    folder_name = os.path.basename(zip_path).replace(".zip", "")
    temp_extract_path = os.path.join(short_temp_path, folder_name)
    os.makedirs(temp_extract_path, exist_ok=True)

    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(temp_extract_path)

    os.makedirs(final_target_path, exist_ok=True)
    entries = os.listdir(temp_extract_path)
    only_entry = os.path.join(temp_extract_path, entries[0])
    if only_entry.endswith(".SAFE") and os.path.isdir(only_entry):
        for item in os.listdir(only_entry):
            shutil.move(os.path.join(only_entry, item), os.path.join(final_target_path, item))
    shutil.rmtree(temp_extract_path)
    return final_target_path


# def convert_bands(safe_path: str, output_dir: str) -> str:
#     os.makedirs(output_dir, exist_ok=True)
#     granule_path = os.path.join(safe_path, "GRANULE")
#     granule_sub = os.listdir(granule_path)[0]
#     img_data_dir = os.path.join(granule_path, granule_sub, "IMG_DATA")

#     band_files = [
#         os.path.join(root, file)
#         for root, _, files in os.walk(img_data_dir)
#         for file in files if file.endswith(".jp2")
#     ]

#     for band_path in band_files:
#         out_name = os.path.basename(band_path).replace(".jp2", ".tif")
#         out_path = os.path.join(output_dir, out_name)
#         with rasterio.open(band_path) as src:
#             profile = src.profile
#             profile.update(driver="GTiff", compress="deflate")
#             with rasterio.open(out_path, "w", **profile) as dst:
#                 dst.write(src.read())
#     return output_dir


def convert_bands(safe_path: str, output_dir: str) -> str:
    print(f"ğŸ¨ Starting band conversion")
    print(f"ğŸ“‚ SAFE path: {safe_path}")
    print(f"ğŸ“ Output dir: {output_dir}")

    os.makedirs(output_dir, exist_ok=True)
    granule_path = os.path.join(safe_path, "GRANULE")
    granule_sub = os.listdir(granule_path)[0]
    img_data_dir = os.path.join(granule_path, granule_sub, "IMG_DATA")

    band_files = [
        os.path.join(root, file)
        for root, _, files in os.walk(img_data_dir)
        for file in files if file.endswith(".jp2")
    ]

    print(f"ğŸ“¸ Found {len(band_files)} .jp2 band files")

    for band_path in band_files:
        out_name = os.path.basename(band_path).replace(".jp2", ".tif")
        out_path = os.path.join(output_dir, out_name)
        with rasterio.open(band_path) as src:
            profile = src.profile
            profile.update(driver="GTiff", compress="deflate")
            with rasterio.open(out_path, "w", **profile) as dst:
                dst.write(src.read())

    # === Generate cloud mask from SCL band ===
    scl_path = next((f for f in band_files if "_SCL_" in f), None)
    if scl_path:
        print(f"ğŸŒ¥ï¸ Found SCL band: {scl_path}")
        scl_out_path = os.path.join(output_dir, "SCL.tif")
        with rasterio.open(scl_path) as src:
            scl_data = src.read(1)

            # Define cloud-related SCL classes: 3 = Cloud shadows, 8â€“11 = various clouds
            cloud_mask = np.isin(scl_data, [3, 8, 9, 10, 11]).astype(np.uint8)

            # Save SCL band
            profile = src.profile.copy()
            profile.update(dtype=rasterio.uint8, count=1, compress="deflate")
            with rasterio.open(scl_out_path, "w", **profile) as dst:
                dst.write(scl_data, 1)
            print(f"ğŸ—ºï¸ Saved SCL band: {scl_out_path}")

            # Save cloud mask
            cloud_out_path = os.path.join(output_dir, "cloud_mask.tif")
            with rasterio.open(cloud_out_path, "w", **profile) as dst:
                dst.write(cloud_mask, 1)
            print(f"ğŸŒ€ Saved cloud mask: {cloud_out_path}")
    else:
        print("âš ï¸ No SCL band found â€” cloud mask will be empty in merged output.")

    return output_dir



# def merge_bands(scene_dir: str, output_path: str) -> str:
#     bands_order = ["B01", "B02", "B03", "B04", "B05", "B06", "B07", "B08", "B8A", "B09", "B11", "B12"]
#     all_tifs = [f for f in os.listdir(scene_dir) if f.endswith(".tif")]
#     sample_path = os.path.join(scene_dir, all_tifs[0])

#     with rasterio.open(sample_path) as src0:
#         meta = src0.meta.copy()
#         meta.update(count=len(bands_order) + 1, driver="GTiff", compress="deflate")

#     os.makedirs(os.path.dirname(output_path), exist_ok=True)

#     with rasterio.open(output_path, "w", **meta) as dst:
#         for idx, band_name in enumerate(bands_order, start=1):
#             band_file = next((f for f in all_tifs if f"_{band_name}_" in f), None)
#             if band_file:
#                 with rasterio.open(os.path.join(scene_dir, band_file)) as src:
#                     dst.write(src.read(1), idx)
#             else:
#                 dst.write(np.zeros((meta["height"], meta["width"]), dtype=meta["dtype"]), idx)

#         cloud_mask_path = os.path.join(scene_dir, "cloud_mask.tif")
#         if os.path.exists(cloud_mask_path):
#             with rasterio.open(cloud_mask_path) as src:
#                 dst.write(src.read(1), len(bands_order) + 1)
#         else:
#             dst.write(np.zeros((meta["height"], meta["width"]), dtype=meta["dtype"]), len(bands_order) + 1)

#     return output_path

def merge_bands(scene_dir: str, output_path: str) -> str:
    print(f"ğŸ§© Starting band merge")
    print(f"ğŸ“‚ Scene dir: {scene_dir}")
    print(f"ğŸ“ Output path: {output_path}")

    bands_order = ["B01", "B02", "B03", "B04", "B05", "B06", "B07", "B08", "B8A", "B09", "B11", "B12"]
    all_tifs = [f for f in os.listdir(scene_dir) if f.endswith(".tif") and not f.startswith("cloud_")]
    
    # Use first valid band to get metadata
    first_band_path = None
    for band_name in bands_order:
        match = next((f for f in all_tifs if f"_{band_name}_" in f), None)
        if match:
            first_band_path = os.path.join(scene_dir, match)
            break

    if not first_band_path:
        raise RuntimeError("âŒ No matching band files found to determine metadata.")

    with rasterio.open(first_band_path) as src0:
        meta = src0.meta.copy()
        meta.update(count=len(bands_order) + 1, driver="GTiff", compress="deflate")

    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with rasterio.open(output_path, "w", **meta) as dst:
        for idx, band_name in enumerate(bands_order, start=1):
            band_file = next((f for f in all_tifs if f"_{band_name}_" in f), None)
            if band_file:
                with rasterio.open(os.path.join(scene_dir, band_file)) as src:
                    data = src.read(1).astype(meta["dtype"])
                    dst.write(data, idx)
                    print(f"  âœ… Added {band_name} to band {idx}")
            else:
                print(f"  âš ï¸ Missing {band_name}, filling with zeros")
                dst.write(np.zeros((meta["height"], meta["width"]), dtype=meta["dtype"]), idx)

        # Add cloud mask as final band
        cloud_mask_path = os.path.join(scene_dir, "cloud_mask.tif")
        if os.path.exists(cloud_mask_path):
            with rasterio.open(cloud_mask_path) as src:
                data = src.read(1).astype(meta["dtype"])
                dst.write(data, len(bands_order) + 1)
                print(f"  â˜ï¸ Added cloud mask as band {len(bands_order) + 1}")
        else:
            print("  âš ï¸ No cloud mask found, writing empty band")
            dst.write(np.zeros((meta["height"], meta["width"]), dtype=meta["dtype"]), len(bands_order) + 1)

    print(f"âœ… Merged bands written to: {output_path}")
    return output_path



def clip_to_aoi(input_tif: str, output_tif: str, aoi_geojson_path: str) -> str:
    aoi = gpd.read_file(aoi_geojson_path)
    with rasterio.open(input_tif) as src:
        aoi_proj = aoi.to_crs(src.crs)
        aoi_geom = aoi_proj.geometry.values
        out_image, out_transform = mask(src, aoi_geom, crop=True)
        out_meta = src.meta.copy()
        out_meta.update({
            "height": out_image.shape[1],
            "width": out_image.shape[2],
            "transform": out_transform
        })

        os.makedirs(os.path.dirname(output_tif), exist_ok=True)
        with rasterio.open(output_tif, "w", **out_meta) as dst:
            dst.write(out_image)
    return output_tif


def generate_maps(input_tif: str, output_dir: str, model_dir: str) -> str:
    os.makedirs(output_dir, exist_ok=True)
    with rasterio.open(input_tif) as src:
        bands = src.read()
        height, width = bands.shape[1:]
        profile = src.profile.copy()
        profile.update(count=1, dtype=rasterio.float32, nodata=np.nan)
        meta = src.meta

    B = {
        "B2": bands[1],
        "B3": bands[2],
        "B4": bands[3],
        "B8": bands[7],
        "B12": bands[11],
    }

    with np.errstate(divide='ignore', invalid='ignore'):
        NDVI = (B["B8"] - B["B4"]) / (B["B8"] + B["B4"])
        NDMI = (B["B8"] - B["B12"]) / (B["B8"] + B["B12"])

    for name, arr in [("ndvi", NDVI), ("ndmi", NDMI)]:
        out_path = os.path.join(output_dir, f"{name}_{os.path.basename(input_tif)}")
        with rasterio.open(out_path, "w", **profile) as dst:
            dst.write(arr.astype(np.float32), 1)

    valid_mask = np.all(bands != 0, axis=0)
    valid_flat = valid_mask.flatten()
    X = bands[:12].transpose(1, 2, 0).reshape(-1, 12)

    # models = {}
    # for nut in ["N", "P", "K"]:
    #     model_path = os.path.join(model_dir, f"rf_model_{nut}.joblib")
    #     models[nut] = joblib.load(model_path)

    # for nut, model in models.items():
    #     y_pred = np.full((height * width), np.nan)
    #     y_pred[valid_flat] = model.predict(X[valid_flat])
    #     y_pred = y_pred.reshape(height, width)
    #     out_path = os.path.join(output_dir, f"{nut}_pred_{os.path.basename(input_tif)}")
    #     with rasterio.open(out_path, "w", **profile) as dst:
    #         dst.write(y_pred.astype(np.float32), 1)

    # # return output_dir
    # for nut, model in models.items():
    #     y_pred = np.full((height * width), np.nan)

    #     if np.count_nonzero(valid_flat) == 0:
    #         print(f"âš ï¸ No valid pixels to predict for {nut}. Skipping.")
    #         continue

    #     try:
    #         y_pred[valid_flat] = model.predict(X[valid_flat])
    #     except Exception as e:
    #         print(f"âŒ Prediction failed for {nut}: {e}")
    #         continue

    #     y_pred = y_pred.reshape(height, width)
    models = {}
    for nut in ["N", "P", "K"]:
        model_path = os.path.join(model_dir, f"rf_model_{nut}.joblib")
        models[nut] = joblib.load(model_path)

    for nut, model in models.items():
        y_pred = np.full((height * width), np.nan)

        if np.count_nonzero(valid_flat) == 0:
            print(f"âš ï¸ No valid pixels to predict for {nut}. Skipping.")
            continue

        try:
            y_pred[valid_flat] = model.predict(X[valid_flat])
        except Exception as e:
            print(f"âŒ Prediction failed for {nut}: {e}")
            continue

        y_pred = y_pred.reshape(height, width)
        out_path = os.path.join(output_dir, f"{nut}_pred_{os.path.basename(input_tif)}")
        with rasterio.open(out_path, "w", **profile) as dst:
            dst.write(y_pred.astype(np.float32), 1)
        print(f"ğŸ§ª Saved {nut} prediction map to {out_path}")



if __name__ == "__main__":
    import sys

    # === STEP 1: Load config & geojson ===
    config_path = sys.argv[1] if len(sys.argv) > 1 else "config/config.yaml"
    config = load_config(config_path)
    geojson = load_geojson(config["aoi"]["geojson_path"])
    creds = config["credentials"]
    date_range = config["date_range"]

    project_name = config["project"]["name"]
    download_dir = config["project"]["download_folder"]
    unzip_dir = os.path.join("unzipped", project_name)
    ind_bands_dir = os.path.join("ind_bands", project_name)
    merged_tif_path = os.path.join("merged", project_name, "merged.tif")
    clipped_tif_path = os.path.join("clipped", project_name, "clipped.tif")
    maps_output_dir = os.path.join("maps", project_name)
    model_dir = config["models"]["directory"]

    # === STEP 2: Get token and search ===
    token = get_token(creds["username"], creds["password"])
    products = search_metadata(token, geojson, date_range["start"], date_range["end"])

    print(f"ğŸ¯ {len(products)} product(s) found.")
    if not products:
        print("âŒ No products found. Exiting.")
        sys.exit(1)
for idx, prod in enumerate(products[:1]):
    product_id = prod["id"]
    print(f"\nğŸ“¦ Processing product {idx+1}/{len(products)}: {product_id}")

    # === Prepare paths and skip flags ===
    paths = {
        "download_dir": download_dir,
        "unzip_dir": unzip_dir,
        "ind_bands_dir": ind_bands_dir,
        "merged_tif_dir": os.path.join("merged", project_name),
        "clipped_tif_dir": os.path.join("clipped", project_name),
        "maps_output_dir": maps_output_dir
    }

    zip_path = os.path.join(download_dir, f"{product_id}.zip")
    safe_path = os.path.join(unzip_dir, f"{product_id}.SAFE")
    band_output = os.path.join(ind_bands_dir, product_id)
    merged_tif = os.path.join(paths["merged_tif_dir"], f"merged_{product_id}.tif")
    clipped_tif = os.path.join(paths["clipped_tif_dir"], f"clipped_{product_id}.tif")
    base_name = os.path.basename(clipped_tif)

    npk_paths = [
        os.path.join(maps_output_dir, f"{prefix}_{base_name}")
        for prefix in ["ndvi", "ndmi", "N_pred", "P_pred", "K_pred"]
    ]

    skip_download = os.path.exists(zip_path)
    skip_unzip = os.path.exists(safe_path)
    # skip_convert = os.path.exists(band_output) and any(f.endswith(".tif") for f in os.listdir(band_output))

    cloud_mask_path = os.path.join(band_output, "cloud_mask.tif")
    skip_convert = os.path.exists(cloud_mask_path)

    skip_merge = os.path.exists(merged_tif)
    skip_clip = os.path.exists(clipped_tif)
    skip_maps = all(os.path.exists(p) for p in npk_paths)

    # === STEP 3: Download
    if skip_download:
        print(f"ğŸ“¦ Skipping download â€” already exists: {zip_path}")
    else:
        print(f"â¬‡ï¸ Downloading product: {product_id}")
        zip_path = download_safe(product_id, token, download_dir)

    # === STEP 4: Unzip
    if skip_unzip:
        print(f"ğŸ“‚ Skipping unzip â€” SAFE folder already exists: {safe_path}")
    else:
        safe_path = unzip_safe(zip_path, safe_path)

    # === STEP 5: Convert Bands
    if skip_convert:
        print(f"ğŸ¨ Skipping band conversion â€” cloud_mask.tif already exists: {cloud_mask_path}")
    else:
        convert_bands(safe_path, band_output)

    # === STEP 6: Merge Bands
    if skip_merge:
        print(f"ğŸ§© Skipping merge â€” already exists: {merged_tif}")
    else:
        merge_bands(band_output, merged_tif)

    # === STEP 7: Clip to AOI
    if skip_clip:
        print(f"âœ‚ï¸ Skipping clipping â€” already exists: {clipped_tif}")
    else:
        clip_to_aoi(merged_tif, clipped_tif, config["aoi"]["geojson_path"])

    # === STEP 8: Generate Maps
    if skip_maps:
        print(f"ğŸ—ºï¸ Skipping map generation â€” all outputs exist.")
    else:
        generate_maps(clipped_tif, maps_output_dir, model_dir)

    print(f"âœ… Finished processing {product_id}")